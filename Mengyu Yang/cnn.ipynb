{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(X,W1,b,conv_param):\n",
    "    out = None\n",
    "    N,H,W = X.shape\n",
    "    F,HH,WW = W1.shape\n",
    "    pad = conv_param[\"pad\"]\n",
    "    stride = conv_param[\"stride\"]\n",
    "    X = np.pad(X, ( (0, 0), (pad, pad),(pad, pad)), 'constant')\n",
    "    Hn = 1 + int((H + 2 * pad - HH) / stride)\n",
    "    Wn = 1 + int((W + 2 * pad - WW) / stride)\n",
    "    out = np.zeros((N,F,Hn,Wn))\n",
    "    for n in range(N):\n",
    "        for m in range(F):\n",
    "            for i in range(Hn):\n",
    "                for j in range(Wn):\n",
    "                    data = X[n,i*stride:i*stride+HH,j*stride:j*stride+WW].reshape(1,-1)\n",
    "                    filt = W1[m].reshape(-1,1)\n",
    "                    out[n,m,i,j] = data.dot(filt)+b[m]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_back(dloss,X,W1,b,conv_param):\n",
    "    N, F, Hn, Wn = dloss.shape\n",
    "    N, H, W = X.shape\n",
    "    F, HH,WW= W1.shape\n",
    "    pad = conv_param[\"pad\"]\n",
    "    stride = conv_param[\"stride\"]\n",
    "    dw = np.zeros_like(W1)\n",
    "    X = np.pad(X,((0,0),(pad,pad),(pad,pad)),'constant')\n",
    "    for n in range(N):\n",
    "        for m in range(F):\n",
    "            for i in range(HH):\n",
    "                for j in range(WW):\n",
    "                    dw[m] += X[n,i*stride:i*stride+HH,j*stride:j*stride+WW]*dloss[n,m,i,j]\n",
    "    db = np.sum(dloss,axis = (0,2,3))\n",
    "    return dw,db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pooling(feature_map,pool_param):\n",
    "#     print(feature_map.shape)\n",
    "    N,C,H,W = feature_map.shape\n",
    "    HH,WW,stride = pool_param['pool_height'],pool_param['pool_width'],pool_param['pool_stride']\n",
    "    Hn = 1 + int((H - HH) / stride)\n",
    "    Wn = 1 + int((W - WW) / stride)\n",
    "    out = np.zeros((N,C,Hn,Wn))\n",
    "    for i in range(Hn):\n",
    "        for j in range(Wn):\n",
    "#             print((np.max(feature_map[...,i*stride:i*stride+HH,j*stride:j*stride+WW],axis=(2,3)).shape))\n",
    "            out[...,i,j] = np.max(feature_map[...,i*stride:i*stride+HH,j*stride:j*stride+WW],axis=(2,3))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pooling_back(dloss,x,out,pool_param):\n",
    "    #还原大小\n",
    "    height,width,stride = pool_param['pool_height'],pool_param['pool_width'],pool_param['pool_stride']\n",
    "    dx = np.zeros_like(x)\n",
    "    N,C,H,W = dloss.shape\n",
    "    for i in range(H):\n",
    "        for j in range(W):\n",
    "            mark = x[...,i*stride:i*stride+height,j*stride:j*stride+width]==out[...,i,j][...,np.newaxis,np.newaxis]\n",
    "            dx[...,i*stride:i*stride+height,j*stride:j*stride+width] = mark*dloss[...,i,j][...,np.newaxis,np.newaxis]\n",
    "    return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(feature_map):\n",
    "    return np.maximum(feature_map,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThreeLayerCNN(object):\n",
    "    def __init__(self,input_dim=(32,32),num_filters=32,filter_size=3,hidden_size=100,\n",
    "                 num_classes=2,reg=0.01,pool_param={'pool_height':2,'pool_stride':2,'pool_width':2},conv_param={}):\n",
    "        self.reg = reg\n",
    "        self.params = {}\n",
    "        self.pool_param = pool_param\n",
    "        if conv_param:\n",
    "            self.conv_param = conv_param\n",
    "        else:\n",
    "            self.conv_param = {'stride':1,'pad':(filter_size-1)//2}\n",
    "        \n",
    "        H,W = input_dim\n",
    "        Hn = (H-filter_size+2*self.conv_param['pad'])//self.conv_param['stride']+1\n",
    "        Wn = (H-filter_size+2*self.conv_param['pad'])//self.conv_param['stride']+1\n",
    "        Hf = (Hn-self.pool_param[\"pool_height\"])//self.pool_param[\"pool_stride\"]+1\n",
    "        Wf = (Wn-self.pool_param[\"pool_width\"])//self.pool_param[\"pool_stride\"]+1\n",
    "        \n",
    "        self.params['W1'] = 0.001*np.random.randn(num_filters,filter_size,filter_size)\n",
    "        self.params['b1'] = np.zeros(num_filters)\n",
    "        self.params['W2'] = 0.001*np.random.randn(num_filters*Hf*Wf,hidden_size)\n",
    "        self.params['b2'] = np.zeros(hidden_size)\n",
    "        self.params['W3'] = 0.001*np.random.randn(hidden_size,num_classes)\n",
    "        self.params['b3'] = np.zeros(num_classes)\n",
    "    def loss(self,X,y=None):\n",
    "        loss = 0\n",
    "        grads = {}\n",
    "        \n",
    "        N = X.shape[0]\n",
    "        reg = self.reg\n",
    "        W1, b1 = self.params['W1'], self.params['b1']\n",
    "        W2, b2 = self.params['W2'], self.params['b2']\n",
    "        W3, b3 = self.params['W3'], self.params['b3']\n",
    "        H1_conv = conv(X,W1,b1,self.conv_param)\n",
    "        H1_tmp = ReLU(H1_conv)\n",
    "        H1 = Pooling(H1_tmp,self.pool_param)\n",
    "        N_,NUM,H,W = H1.shape\n",
    "        flatten = H1.reshape(H1.shape[0],-1)\n",
    "        H2 = ReLU(flatten.dot(W2)+b2)\n",
    "        scores = H2.dot(W3)+b3\n",
    "        h_x = sigmoid(scores)\n",
    "        tmp1 = -np.log(h_x).T*y\n",
    "        tmp1 = tmp1.T\n",
    "        tmp2 = (1-y)*np.log(1-h_x).T\n",
    "        tmp2 = tmp2.T\n",
    "#         print(tmp1.shape,tmp2.shape)\n",
    "        tmp3 = tmp1-tmp2\n",
    "        loss = np.sum(tmp1-tmp2)/N\n",
    "        loss += 0.5*self.reg*(np.sum(W3**2)+np.sum(W2**2)+np.sum(W3**2))\n",
    "        \n",
    "        y_ = y.reshape(-1,1)\n",
    "        dW3 = (np.dot(H2.T,(h_x-y_)))/N + 0.5*reg*W3\n",
    "        tmp = np.mat(H2.T+0.0001*np.random.rand(H2.shape[0],H2.shape[1]))\n",
    "        tmp = tmp.I\n",
    "        tmp = np.array(tmp)\n",
    "        dscores = tmp.dot(dW3)\n",
    "        db3 = np.sum(dscores,axis = 0)/N\n",
    "\n",
    "        dW2_tmp = dscores.dot(dW3.T)\n",
    "        dW2_tmp[H2==0]=0\n",
    "        dW2 = flatten.T.dot(dW2_tmp) + 0.5*reg*W2\n",
    "        db2 = np.sum(dW2_tmp,axis = 0)/N\n",
    "        \n",
    "        dflatten = dW2_tmp.dot(W2.T)\n",
    "        dH1 = dflatten.reshape(N_,NUM,H,W)\n",
    "        dH1_conv = Pooling_back(dH1,H1_tmp,H1,self.pool_param)\n",
    "        dre = dH1_conv\n",
    "        dH1_conv[H1_tmp==0] = 0\n",
    "        dW1,db1 = conv_back(dH1_conv,X,W1,b1,self.conv_param)\n",
    "        dW1 += 0.5*reg*W1\n",
    "        \n",
    "        grads['W1'],grads['W2'],grads['W3'] = dW1,dW2,dW3\n",
    "        grads['b1'],grads['b2'],grads['b3'] = db1,db2,db3\n",
    "        \n",
    "        return loss, grads\n",
    "    \n",
    "    def train(self,X,y,learning_rate=1e-3,batch_size=100,num_iter=10,learning_rate_decay=0.95):\n",
    "        num_train = X.shape[0]\n",
    "        loss_history = []\n",
    "        train_acc_history = []\n",
    "        iterations_per_epoch = max(1,int(num_train/batch_size))\n",
    "        \n",
    "        for it in range(num_iter):\n",
    "            indices = np.random.choice(num_train,batch_size,replace=True)\n",
    "            x_batch = X[indices]\n",
    "            y_batch = y[indices]\n",
    "            \n",
    "            loss, grads = self.loss(x_batch, y_batch)\n",
    "            loss_history.append(loss)\n",
    "            self.params['W1'] -= learning_rate*grads['W1']\n",
    "            self.params['W2'] -= learning_rate*grads['W2']\n",
    "            self.params['W3'] -= learning_rate*grads['W3']\n",
    "            self.params['b1'] -= learning_rate*grads['b1']\n",
    "            self.params['b2'] -= learning_rate*grads['b2']\n",
    "            self.params['b3'] -= learning_rate*grads['b3']\n",
    "            \n",
    "            if it % iterations_per_epoch == 0:\n",
    "                train_acc = (self.predict(x_batch) == y_batch).mean()\n",
    "                train_acc_history.append(train_acc)\n",
    "                learning_rate *= learning_rate_decay\n",
    "\n",
    "        return {'loss_history': loss_history,'train_acc_history': train_acc_history }\n",
    "                                   \n",
    "    def predict(self,X):\n",
    "        W1, b1 = self.params['W1'], self.params['b1']\n",
    "        W2, b2 = self.params['W2'], self.params['b2']\n",
    "        W3, b3 = self.params['W3'], self.params['b3']\n",
    "        tmp = Pooling(ReLU(conv(X,W1,b1,self.conv_param)),self.pool_param)\n",
    "        N,F,H,W = tmp.shape\n",
    "        flatten = tmp.reshape(tmp.shape[0],-1)\n",
    "        H2 = ReLU(flatten.dot(W2)+b2)\n",
    "        scores = H2.dot(W3)+b3\n",
    "        pred = np.argmax(scores,axis = 1)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_file = pd.read_csv(\"MURA-v1.1/train_image_paths.csv\",header = None)\n",
    "X_valid_file = pd.read_csv(\"MURA-v1.1/valid_image_paths.csv\",header = None)\n",
    "y_file = pd.read_csv(\"MURA-v1.1/train_labeled_studies.csv\",header = None,index_col=0)\n",
    "y_valid_file = pd.read_csv(\"MURA-v1.1/valid_labeled_studies.csv\",header = None,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 1000\n",
    "test_size = 300\n",
    "img_size = (32,32)\n",
    "X = []\n",
    "y = []\n",
    "test_X = []\n",
    "test_y = []\n",
    "for i in range(train_size):\n",
    "    file = X_file[0].iloc[i]\n",
    "    img = cv2.imread(file,0)\n",
    "    img = cv2.resize(img,img_size)\n",
    "    file = file[:-10]\n",
    "    try:\n",
    "        label = y_file.loc[file,1]\n",
    "    except :\n",
    "        pass\n",
    "    else:\n",
    "        X.append(img)\n",
    "        y.append(label)\n",
    "for i in range(test_size):\n",
    "    file = X_valid_file[0].iloc[i]\n",
    "    img = cv2.imread(file,0)\n",
    "    img = cv2.resize(img,img_size)\n",
    "    file = file[:-10]\n",
    "    try:\n",
    "        label = y_valid_file.loc[file,1]\n",
    "    except :\n",
    "        pass\n",
    "    else:\n",
    "        test_X.append(img)\n",
    "        test_y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 32, 32) (1000,) (300, 32, 32) (300,)\n"
     ]
    }
   ],
   "source": [
    "X,y = np.array(X),np.array(y)\n",
    "test_X,test_y = np.array(test_X),np.array(test_y)\n",
    "print(X.shape,y.shape,test_X.shape,test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss_history': [1.390453802507708,\n",
       "  1.390453494952003,\n",
       "  1.3904507870868164,\n",
       "  1.390457979932719,\n",
       "  1.3904673707811053,\n",
       "  1.3904657881090239,\n",
       "  1.3904461973176292,\n",
       "  1.3904453387982116,\n",
       "  1.3904312850185916,\n",
       "  1.3904039933015155],\n",
       " 'train_acc_history': [0.07]}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = ThreeLayerCNN()\n",
    "net.train(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<built-in method mean of numpy.ndarray object at 0x0000018E24CF8B20>\n"
     ]
    }
   ],
   "source": [
    "pred = net.predict(test_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11\n"
     ]
    }
   ],
   "source": [
    "print((pred==test_y).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
